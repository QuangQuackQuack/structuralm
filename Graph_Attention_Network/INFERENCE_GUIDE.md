# H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng Model GAT Layout Prediction

## üìã M√¥ T·∫£

Model **LayoutGAT** l√† m·ªôt m√¥ h√¨nh Graph Attention Network (GAT) ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ d·ª± ƒëo√°n v·ªã tr√≠ (position) v√† h∆∞·ªõng (rotation) c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng trong m·ªôt c·∫£nh 3D d·ª±a tr√™n:
- **Th√¥ng tin ƒë·ªëi t∆∞·ª£ng**: Lo·∫°i ƒë·ªëi t∆∞·ª£ng (class), k√≠ch th∆∞·ªõc bounding box
- **Quan h·ªá kh√¥ng gian**: C√°c m·ªëi quan h·ªá gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng (left_of, on_top_of, behind, etc.)

Model s·ª≠ d·ª•ng ki·∫øn tr√∫c GATv2 v·ªõi nhi·ªÅu layer attention ƒë·ªÉ h·ªçc c√°c m·ªëi quan h·ªá ph·ª©c t·∫°p v√† sinh layout h·ª£p l√Ω cho scene.

---

## üöÄ C√†i ƒê·∫∑t M√¥i Tr∆∞·ªùng

### 1. Y√™u C·∫ßu H·ªá Th·ªëng

- **Python**: 3.8 ho·∫∑c cao h∆°n
- **CUDA** (t√πy ch·ªçn): ƒê·ªÉ tƒÉng t·ªëc ƒë·ªô inference v·ªõi GPU
  - Ki·ªÉm tra CUDA: `nvidia-smi`
- **H·ªá ƒëi·ªÅu h√†nh**: Windows, Linux, ho·∫∑c macOS

### 2. C√†i ƒê·∫∑t Dependencies

```bash
# C√†i ƒë·∫∑t c√°c package c·∫ßn thi·∫øt
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install torch-geometric
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
pip install pyyaml tqdm numpy
```

**L∆∞u √Ω**: 
- N·∫øu d√πng CPU, b·ªè qua `--index-url` v√† c√†i torch th√¥ng th∆∞·ªùng
- ƒêi·ªÅu ch·ªânh phi√™n b·∫£n CUDA (`cu118`) ph√π h·ª£p v·ªõi m√°y c·ªßa b·∫°n

### 3. Ki·ªÉm Tra C√†i ƒê·∫∑t

```python
import torch
import torch_geometric
print(f"PyTorch version: {torch.__version__}")
print(f"PyG version: {torch_geometric.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
```

---

## üìÅ C·∫•u Tr√∫c Th∆∞ M·ª•c

```
gat_training_syn/
‚îú‚îÄ‚îÄ inference.py              # Script inference ch√≠nh
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ configs_syn.yaml      # File c·∫•u h√¨nh model
‚îú‚îÄ‚îÄ checkpoints/              # Th∆∞ m·ª•c ch·ª©a model ƒë√£ train
‚îÇ   ‚îú‚îÄ‚îÄ model_phase1234.pt    # Model full (khuy√™n d√πng)
‚îÇ   ‚îú‚îÄ‚îÄ model_phase123.pt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ model.py              # ƒê·ªãnh nghƒ©a LayoutGAT
‚îÇ   ‚îú‚îÄ‚îÄ mappings.py           # Mapping class & relations
‚îÇ   ‚îî‚îÄ‚îÄ utils.py              # Utilities
‚îú‚îÄ‚îÄ examples/                 # (T·∫°o th∆∞ m·ª•c n√†y ƒë·ªÉ ch·ª©a v√≠ d·ª•)
‚îÇ   ‚îî‚îÄ‚îÄ sample_scene.json     # File scene m·∫´u
‚îî‚îÄ‚îÄ INFERENCE_GUIDE.md        # File n√†y
```

---

## üìù ƒê·ªãnh D·∫°ng Input: scene.json

### C·∫•u Tr√∫c JSON

File `scene.json` c·∫ßn c√≥ c·∫•u tr√∫c nh∆∞ sau:

```json
{
  "objects": [
    {
      "id": 0,
      "label": "Bed",
      "normalized_bounding_box": [0.9876, 0.3688, 0.7973],
      "normalized_relative_center": [0.0, 0.0, 0.0],
      "rot": [1.0, 0.0, 0.0, 0.0]
    },
    {
      "id": 1,
      "label": "Chair",
      "normalized_bounding_box": [0.4435, 0.9959, 0.3451]
    }
  ],
  "relationships": [
    {
      "obj_id1": 1,
      "obj_id2": 0,
      "relation": "left_of"
    }
  ]
}
```

### M√¥ T·∫£ C√°c Field

#### **objects** (b·∫Øt bu·ªôc)
Danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng trong scene.

- **`id`** (int, b·∫Øt bu·ªôc): ID duy nh·∫•t c·ªßa ƒë·ªëi t∆∞·ª£ng (b·∫Øt ƒë·∫ßu t·ª´ 0)
- **`label`** (string, b·∫Øt bu·ªôc): Lo·∫°i ƒë·ªëi t∆∞·ª£ng. C√°c gi√° tr·ªã h·ª£p l·ªá:
  ```
  "Armchair", "Banana", "Basket", "Bed", "Cabinet", "Cake", "Carpet", 
  "Chair", "Cup", "Easel", "Fan", "Fridge", "Floor_lamp", "Laptop_close", 
  "Laptop_open", "Lighting", "Mirror", "Monkey", "Panda", "Piano", 
  "Picture", "Pier", "Pillow", "Rabbit", "Sofa", "TV", "Table", "Test", 
  "Toy", "Tree", "Vase", "Wardrobe", "Washingmachine", "human_lying", 
  "human_sitting", "human_standing", "Other"
  ```
  *(N·∫øu label kh√¥ng c√≥ trong danh s√°ch, s·∫Ω ƒë∆∞·ª£c map sang "Other")*

- **`normalized_bounding_box`** (array[3], b·∫Øt bu·ªôc): K√≠ch th∆∞·ªõc bounding box ƒë√£ chu·∫©n h√≥a
  - Format: `[width, height, depth]`
  - Gi√° tr·ªã t·ª´ 0.0 ƒë·∫øn ~1.0 (t·ª∑ l·ªá so v·ªõi k√≠ch th∆∞·ªõc ph√≤ng)
  - V√≠ d·ª•: `[0.5, 0.3, 0.4]` = 50% chi·ªÅu r·ªông ph√≤ng, 30% chi·ªÅu cao, 40% chi·ªÅu s√¢u

- **`normalized_relative_center`** (array[3], optional): V·ªã tr√≠ ban ƒë·∫ßu (n·∫øu c√≥)
  - Format: `[x, y, z]`
  - Th∆∞·ªùng d√πng cho anchor object (object ƒë·∫ßu ti√™n, id=0)
  - **Anchor n√™n ƒë·∫∑t t·∫°i `[0.0, 0.0, 0.0]`** ƒë·ªÉ model ho·∫°t ƒë·ªông t·ªët nh·∫•t

- **`rot`** (array[4], optional): Rotation ban ƒë·∫ßu d∆∞·ªõi d·∫°ng quaternion
  - Format: `[w, x, y, z]`
  - V√≠ d·ª•: `[1.0, 0.0, 0.0, 0.0]` = kh√¥ng rotation

- **`name`** (string, optional): T√™n ƒë·ªëi t∆∞·ª£ng (ƒë·ªÉ d·ªÖ ƒë·ªçc k·∫øt qu·∫£)

#### **relationships** (optional, nh∆∞ng n√™n c√≥)
Danh s√°ch c√°c m·ªëi quan h·ªá kh√¥ng gian gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng.

- **`obj_id1`** (int, b·∫Øt bu·ªôc): ID c·ªßa ƒë·ªëi t∆∞·ª£ng th·ª© nh·∫•t
- **`obj_id2`** (int, b·∫Øt bu·ªôc): ID c·ªßa ƒë·ªëi t∆∞·ª£ng th·ª© hai  
- **`relation`** (string, b·∫Øt bu·ªôc): Lo·∫°i quan h·ªá. C√°c gi√° tr·ªã h·ª£p l·ªá:
  ```
  "on_top_of", "above", "under", "left_of", "right_of", 
  "in_front_of", "behind", "facing", "in"
  ```

**L∆∞u √Ω**:
- Model t·ª± ƒë·ªông t·∫°o bidirectional edges (c·∫°nh hai chi·ªÅu)
- N·∫øu kh√¥ng c√≥ relationships, model v·∫´n ch·∫°y nh∆∞ng k·∫øt qu·∫£ k√©m ch√≠nh x√°c

---

## üì§ ƒê·ªãnh D·∫°ng Output

### C·∫•u Tr√∫c JSON Output

File output (m·∫∑c ƒë·ªãnh: `<scene>_predictions.json`) c√≥ c·∫•u tr√∫c:

```json
{
  "metadata": {
    "model": "LayoutGAT",
    "num_objects": 2,
    "device": "cuda"
  },
  "predictions": [
    {
      "id": 0,
      "name": "Bed_0",
      "label": "Bed",
      "input": {
        "bounding_box": [0.9876, 0.3688, 0.7973],
        "position": [0.0, 0.0, 0.0],
        "rotation": [1.0, 0.0, 0.0, 0.0]
      },
      "prediction": {
        "position": [0.0, 0.0, 0.0],
        "rotation_quaternion": [0.9998, -0.0045, 0.0189, 0.0021],
        "rotation_format": "xyzw"
      }
    },
    {
      "id": 1,
      "name": "Chair_1",
      "label": "Chair",
      "input": {
        "bounding_box": [0.4435, 0.9959, 0.3451]
      },
      "prediction": {
        "position": [-1.2534, 0.0123, 0.4567],
        "rotation_quaternion": [0.7071, 0.0, 0.7071, 0.0],
        "rotation_format": "xyzw"
      }
    }
  ]
}
```

### M√¥ T·∫£ Output

- **`position`**: V·ªã tr√≠ d·ª± ƒëo√°n trong kh√¥ng gian 3D
  - Format: `[x, y, z]`
  - Gi√° tr·ªã trong kho·∫£ng [-2.0, 2.0] (t√πy room_scale trong config)
  - ƒê∆°n v·ªã: t∆∞∆°ng ƒë·ªëi so v·ªõi k√≠ch th∆∞·ªõc ph√≤ng chu·∫©n h√≥a

- **`rotation_quaternion`**: Rotation d·ª± ƒëo√°n d∆∞·ªõi d·∫°ng quaternion
  - Format: `[w, x, y, z]`
  - ƒê√£ ƒë∆∞·ª£c normalize (|q| = 1)

---

## üéØ C√°ch S·ª≠ D·ª•ng

### Ph∆∞∆°ng Ph√°p 1: Command Line (Khuy√™n D√πng)

```bash
# C√∫ ph√°p c∆° b·∫£n
python inference.py --scene <path_to_scene.json> --checkpoint <path_to_checkpoint.pt>

# V√≠ d·ª• ƒë·∫ßy ƒë·ªß
python inference.py \
    --scene examples/sample_scene.json \
    --checkpoint checkpoints/model_phase1234.pt \
    --config configs/configs_syn.yaml \
    --output results/my_predictions.json
```

**C√°c tham s·ªë**:
- `--scene` (b·∫Øt bu·ªôc): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file scene.json
- `--checkpoint`: ƒê∆∞·ªùng d·∫´n checkpoint (m·∫∑c ƒë·ªãnh: `checkpoints/model_phase1234.pt`)
- `--config`: ƒê∆∞·ªùng d·∫´n config (m·∫∑c ƒë·ªãnh: `configs/configs_syn.yaml`)
- `--output`: ƒê∆∞·ªùng d·∫´n file output (m·∫∑c ƒë·ªãnh: `<scene>_predictions.json`)

### Ph∆∞∆°ng Ph√°p 2: Python Script

```python
from inference import SceneInference

# Kh·ªüi t·∫°o inferencer
inferencer = SceneInference(
    checkpoint_path='checkpoints/model_phase1234.pt',
    config_path='configs/configs_syn.yaml'
)

# Run inference
predictions = inferencer.run_inference(
    scene_json_path='examples/sample_scene.json',
    output_path='results/output.json'
)

# Predictions tr·∫£ v·ªÅ tuple (positions, rotations)
positions, rotations = predictions
print(f"Predicted {len(positions)} objects")
```

### Ph∆∞∆°ng Ph√°p 3: Batch Processing

```python
import glob
from inference import SceneInference

inferencer = SceneInference('checkpoints/model_phase1234.pt')

# Process t·∫•t c·∫£ scene trong th∆∞ m·ª•c
scene_files = glob.glob('examples/*.json')
for scene_file in scene_files:
    print(f"\nProcessing: {scene_file}")
    inferencer.run_inference(scene_file)
```

---

## üìä V√≠ D·ª• Th·ª±c T·∫ø

### V√≠ D·ª• 1: Scene ƒê∆°n Gi·∫£n (2 Objects)

**Input**: `examples/simple_scene.json`
```json
{
  "objects": [
    {
      "id": 0,
      "label": "Table",
      "normalized_bounding_box": [0.8, 0.4, 0.6],
      "normalized_relative_center": [0.0, 0.0, 0.0],
      "rot": [1.0, 0.0, 0.0, 0.0]
    },
    {
      "id": 1,
      "label": "Chair",
      "normalized_bounding_box": [0.45, 0.95, 0.35]
    }
  ],
  "relationships": [
    {
      "obj_id1": 1,
      "obj_id2": 0,
      "relation": "in_front_of"
    }
  ]
}
```

**Ch·∫°y**:
```bash
python inference.py --scene examples/simple_scene.json
```

**Output Console**:
```
Loading model from checkpoints/model_phase1234.pt...
Model loaded successfully on cuda
Loaded scene with 2 objects and 1 relationships
Converting scene to graph...
Graph: 2 nodes, 2 edges
Running inference...

============================================================
PREDICTION RESULTS
============================================================

Object 0: Table
  Position: [0.0000, 0.0000, 0.0000]
  Rotation: [0.9987, 0.0023, -0.0145, 0.0489]

Object 1: Chair
  Position: [-0.8523, 0.0234, -1.2341]
  Rotation: [0.7123, 0.0034, 0.7018, -0.0012]
============================================================

Results saved to: examples/simple_scene_predictions.json
```

### V√≠ D·ª• 2: Scene Ph·ª©c T·∫°p (Living Room)

**Input**: `examples/living_room.json`
```json
{
  "objects": [
    {"id": 0, "label": "Sofa", "normalized_bounding_box": [1.2, 0.5, 0.8]},
    {"id": 1, "label": "TV", "normalized_bounding_box": [0.7, 0.4, 0.05]},
    {"id": 2, "label": "Table", "normalized_bounding_box": [0.6, 0.3, 0.6]},
    {"id": 3, "label": "Carpet", "normalized_bounding_box": [1.5, 0.01, 1.2]}
  ],
  "relationships": [
    {"obj_id1": 1, "obj_id2": 0, "relation": "in_front_of"},
    {"obj_id1": 2, "obj_id2": 0, "relation": "in_front_of"},
    {"obj_id1": 3, "obj_id2": 0, "relation": "under"},
    {"obj_id1": 3, "obj_id2": 2, "relation": "under"}
  ]
}
```

---

## ‚öôÔ∏è C·∫•u H√¨nh Model (configs_syn.yaml)

C√°c tham s·ªë quan tr·ªçng:

```yaml
model:
  num_classes: 37           # S·ªë l∆∞·ª£ng class objects
  embedding_dim: 64         # Dimension c·ªßa class embedding
  hidden_dim: 256           # Hidden dimension c·ªßa GAT
  num_heads: 4              # S·ªë attention heads
  num_gat_layers: 4         # S·ªë layer GAT
  room_scale: 2.0           # Scale c·ªßa output position ([-2, 2])
  dropout_rate: 0.1

training:
  device: "cuda"            # "cuda" ho·∫∑c "cpu"
```

**L∆∞u √Ω**: Kh√¥ng n√™n thay ƒë·ªïi c√°c tham s·ªë n√†y tr·ª´ khi b·∫°n mu·ªën retrain model.

---

## üêõ Troubleshooting

### L·ªói: "CUDA out of memory"
**Gi·∫£i ph√°p**:
```bash
# S·ª≠ d·ª•ng CPU thay v√¨ GPU
# S·ª≠a trong configs/configs_syn.yaml:
training:
  device: "cpu"
```

### L·ªói: "Unknown class label"
**Gi·∫£i ph√°p**: Ki·ªÉm tra l·∫°i `label` trong scene.json. N·∫øu kh√¥ng c√≥ trong danh s√°ch CLASS_MAPPING, s·∫Ω t·ª± ƒë·ªông map sang "Other".

### L·ªói: "No module named 'torch_geometric'"
**Gi·∫£i ph√°p**:
```bash
pip install torch-geometric
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
```

### K·∫øt qu·∫£ prediction kh√¥ng t·ªët
**Nguy√™n nh√¢n & Gi·∫£i ph√°p**:
1. **Thi·∫øu relationships**: Th√™m nhi·ªÅu quan h·ªá kh√¥ng gian gi·ªØa objects
2. **Anchor kh√¥ng ƒë√∫ng**: ƒê·∫£m b·∫£o object ƒë·∫ßu ti√™n (id=0) c√≥ position [0,0,0]
3. **Bounding box kh√¥ng chu·∫©n**: Ki·ªÉm tra l·∫°i normalization (gi√° tr·ªã 0-1)
4. **Checkpoint kh√¥ng ph√π h·ª£p**: Th·ª≠ c√°c checkpoint kh√°c (phase1, phase123, phase1234)

---

## üìà Model Checkpoints

C√°c checkpoint c√≥ s·∫µn:

| Checkpoint | M√¥ T·∫£ | Khuy√™n D√πng |
|-----------|-------|-------------|
| `model_phase1.pt` | Base model, train tr√™n Phase 1 | Scene ƒë∆°n gi·∫£n (2-3 objects) |
| `model_phase123.pt` | Train l≈©y ti·∫øn Phase 1‚Üí2‚Üí3 | Scene trung b√¨nh (3-5 objects) |
| `model_phase1234.pt` | Full model, train tr√™n t·∫•t c·∫£ Phase | **Scene ph·ª©c t·∫°p (5+ objects)** ‚≠ê |
| `model_phase123_finetune.pt` | Fine-tuned t·ª´ Phase 123 | Alternate choice |

**Khuy·∫øn ngh·ªã**: S·ª≠ d·ª•ng `model_phase1234.pt` cho k·∫øt qu·∫£ t·ªët nh·∫•t.

---

## üîß N√¢ng Cao

### T√πy Ch·ªânh Class Mapping

N·∫øu mu·ªën th√™m class m·ªõi, ch·ªânh s·ª≠a `src/mappings.py`:

```python
CLASS_MAPPING = {
    # ... existing classes ...
    "MyNewClass": 37,  # ID ti·∫øp theo
    "Other": 38        # Update Other ID
}
NUM_CLASSES = 39  # Update total
```

**L∆∞u √Ω**: Sau khi thay ƒë·ªïi c·∫ßn **retrain model**.

### Visualization (T√πy Ch·ªçn)

ƒê·ªÉ visualize k·∫øt qu·∫£ prediction trong 3D:

```python
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load predictions
with open('output_predictions.json', 'r') as f:
    data = json.load(f)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

for obj in data['predictions']:
    pos = obj['prediction']['position']
    ax.scatter(pos[0], pos[1], pos[2], s=100, label=obj['label'])
    ax.text(pos[0], pos[1], pos[2], obj['name'])

ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.legend()
plt.show()
```

---

## üìö References & Citation

Model n√†y s·ª≠ d·ª•ng:
- **GATv2** (Graph Attention Networks v2): Brody et al., 2021
- **PyTorch Geometric**: Fey & Lenssen, 2019

N·∫øu s·ª≠ d·ª•ng model n√†y trong nghi√™n c·ª©u, vui l√≤ng tr√≠ch d·∫´n:

```bibtex
@misc{layoutgat2025,
  title={LayoutGAT: Graph Attention Networks for 3D Scene Layout Generation},
  author={Your Name},
  year={2025}
}
```

---

## üìû Li√™n H·ªá & H·ªó Tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ ho·∫∑c c√≥ c√¢u h·ªèi:
1. Ki·ªÉm tra l·∫°i **Troubleshooting** section
2. Xem l·∫°i **ƒê·ªãnh D·∫°ng Input** ƒë·ªÉ ƒë·∫£m b·∫£o JSON ƒë√∫ng format
3. Th·ª≠ v·ªõi **v√≠ d·ª• ƒë∆°n gi·∫£n** tr∆∞·ªõc khi test scene ph·ª©c t·∫°p

---

## üìÑ License

Project n√†y ch·ªâ d√πng cho m·ª•c ƒë√≠ch h·ªçc t·∫≠p v√† nghi√™n c·ª©u.

---

**Happy Inferencing! üéâ**
